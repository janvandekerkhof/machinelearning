{
 "metadata": {
  "name": "",
  "signature": "sha256:c2bbb4524f9661faa25116231c080c76834f36a6dfee239e6f7277a8be8fd86c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Machine Learning Lab 1 - Jan van de Kerkhof\n",
      "### 2015-09-08\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from dtree import entropy, averageGain, select, mostCommon, buildTree, check, allPruned\n",
      "from pandas import DataFrame\n",
      "import monkdata as m\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assingment 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entropies = [entropy(m.monk1), entropy(m.monk2), entropy(m.monk3)]\n",
      "d = [\n",
      "    [\"MONK1\", entropies[0]],\n",
      "    [\"MONK2\", entropies[1]],\n",
      "    [\"MONK3\", entropies[2]],\n",
      "]\n",
      "df = DataFrame(d, columns=[\"DataSet\", \"DataFrame\"])\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DataSet</th>\n",
        "      <th>DataFrame</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>MONK1</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>MONK2</td>\n",
        "      <td>0.957117</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>MONK3</td>\n",
        "      <td>0.999806</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "  DataSet  DataFrame\n",
        "0   MONK1   1.000000\n",
        "1   MONK2   0.957117\n",
        "2   MONK3   0.999806"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assignment 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['DataSet', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6']\n",
      "datasets = [m.monk1, m.monk2, m.monk3]\n",
      "dataset_labels = ['MONK1', 'MONK2', 'MONK3']\n",
      "d = []\n",
      "for i in range(0, len(datasets)):\n",
      "    gains = [dataset_labels[i]]\n",
      "    for j in range(0,len(m.attributes)):\n",
      "        gains.append(averageGain(datasets[i], m.attributes[j]))\n",
      "    d.append(gains)\n",
      "\n",
      "df = DataFrame(d, columns=columns)\n",
      "df\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DataSet</th>\n",
        "      <th>a1</th>\n",
        "      <th>a2</th>\n",
        "      <th>a3</th>\n",
        "      <th>a4</th>\n",
        "      <th>a5</th>\n",
        "      <th>a6</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>MONK1</td>\n",
        "      <td>0.075273</td>\n",
        "      <td>0.005838</td>\n",
        "      <td>0.004708</td>\n",
        "      <td>0.026312</td>\n",
        "      <td>0.287031</td>\n",
        "      <td>0.000758</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>MONK2</td>\n",
        "      <td>0.003756</td>\n",
        "      <td>0.002458</td>\n",
        "      <td>0.001056</td>\n",
        "      <td>0.015664</td>\n",
        "      <td>0.017277</td>\n",
        "      <td>0.006248</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>MONK3</td>\n",
        "      <td>0.007121</td>\n",
        "      <td>0.293736</td>\n",
        "      <td>0.000831</td>\n",
        "      <td>0.002892</td>\n",
        "      <td>0.255912</td>\n",
        "      <td>0.007077</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "  DataSet        a1        a2        a3        a4        a5        a6\n",
        "0   MONK1  0.075273  0.005838  0.004708  0.026312  0.287031  0.000758\n",
        "1   MONK2  0.003756  0.002458  0.001056  0.015664  0.017277  0.006248\n",
        "2   MONK3  0.007121  0.293736  0.000831  0.002892  0.255912  0.007077"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on these results, we should select attribute **a5** for splitting examples at the root node, as **a5** displays the highest information gain."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assignment 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['Node', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6']\n",
      "a5_values = range(1,5)\n",
      "splits = {}\n",
      "d = []\n",
      "for val in a5_values:\n",
      "    split = select(datasets[0], m.attributes[4], val)\n",
      "    splits[val] = split\n",
      "    gains = [(\"Node%d\" % val)]\n",
      "    for i in range(0,len(m.attributes)):\n",
      "        gains.append(averageGain(split, m.attributes[i]))\n",
      "    d.append(gains)\n",
      "\n",
      "df = DataFrame(d, columns=columns)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Node</th>\n",
        "      <th>a1</th>\n",
        "      <th>a2</th>\n",
        "      <th>a3</th>\n",
        "      <th>a4</th>\n",
        "      <th>a5</th>\n",
        "      <th>a6</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>Node1</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>Node2</td>\n",
        "      <td>0.040217</td>\n",
        "      <td>0.015063</td>\n",
        "      <td>0.037273</td>\n",
        "      <td>0.048892</td>\n",
        "      <td>0</td>\n",
        "      <td>0.025807</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Node3</td>\n",
        "      <td>0.033055</td>\n",
        "      <td>0.002197</td>\n",
        "      <td>0.017982</td>\n",
        "      <td>0.019123</td>\n",
        "      <td>0</td>\n",
        "      <td>0.045109</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>Node4</td>\n",
        "      <td>0.206291</td>\n",
        "      <td>0.033898</td>\n",
        "      <td>0.025906</td>\n",
        "      <td>0.075933</td>\n",
        "      <td>0</td>\n",
        "      <td>0.003324</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "    Node        a1        a2        a3        a4  a5        a6\n",
        "0  Node1  0.000000  0.000000  0.000000  0.000000   0  0.000000\n",
        "1  Node2  0.040217  0.015063  0.037273  0.048892   0  0.025807\n",
        "2  Node3  0.033055  0.002197  0.017982  0.019123   0  0.045109\n",
        "3  Node4  0.206291  0.033898  0.025906  0.075933   0  0.003324"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For **Node1** there is no attribute that gives more information gain, a leaf node has been reached.\n",
      "\n",
      "For **Node2** attribute **a4** gives the most information gain.\n",
      "\n",
      "For **Node3** attribute **a1** gives the most information gain.\n",
      "\n",
      "For **Node4** attribute **a1** gives the most information gain.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "commons = []\n",
      "for val in splits:\n",
      "    commons.append(mostCommon(splits[val]))\n",
      "    \n",
      "print 'Labels for nodes %s' % commons\n",
      "tree = buildTree(datasets[0], m.attributes, maxdepth=1)\n",
      "print 'Tree: %s' % tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Labels for nodes [True, False, False, False]\n",
        "Tree: A5(+---)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The *buildTree* method prints exactly the first two levels of the tree. (I used the print statement because I couldn't get PyQt4 installed)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = []\n",
      "testsets = [m.monk1test, m.monk2test, m.monk3test]\n",
      "columns = [\"DataSet\", \"E_train\", \"E_test\"]\n",
      "d = []\n",
      "for i in range(0, len(datasets)):\n",
      "    row = [dataset_labels[i]]\n",
      "    trees.append(buildTree(datasets[i], m.attributes))\n",
      "    row.append(check(trees[i], datasets[i]))\n",
      "    row.append(check(trees[i], testsets[i]))\n",
      "    d.append(row)\n",
      "\n",
      "for i in range(0, len(trees)):\n",
      "    print 'Tree%s: \\n %s' % (i, trees[i])\n",
      "    \n",
      "df = DataFrame(d, columns=columns)\n",
      "df\n",
      "\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tree0: \n",
        " A5(+A4(A1(A2(+--)A2(-++)A2(--+))A2(-+-)A3(A1(A2(+--)+A2(-++))A2(--A1(--+))))A6(A4(A3(A1(A2(+--)A2(-+-)-)-)A1(A2(+--)--)-)A3(A4(A1(+--)A1(-++)+)A1(-A2(-+-)A2(--+))))A1(A2(+--)A2(-+-)A2(+-+)))\n",
        "Tree1: \n",
        " A5(A3(A6(-A1(-A2(--A4(--+))A2(-A4(-+-)-)))A4(A2(--A1(-+-))+A1(A2(-A6(-+)-)A2(A6(-+)++)+)))A3(A4(A2(-+-)A6(A1(--+)+)A1(A2(-++)++))A2(A4(++A1(+-A6(+-)))-A1(+A4(+--)-)))A3(A6(A1(-A4(-++)A4(--+))A2(+A1(+-A4(+--))A4(A1(-++)A1(+--)-)))A4(A2(A6(-+)A6(+-)A1(A6(-+)++))A1(A2(-+-)--)A1(A6(+-)--)))A2(A6(-A1(+-A4(++-)))A1(A4(-A3(-+)A3(A6(-+)A6(+-)))A3(+A6(+-))-)A3(A4(--+)-)))\n",
        "Tree2: \n",
        " A2(A5(++A4(A1(--+)++)-)A5(+A1(+A4(+-+)+)A3(A4(+A1(--+)A1(+--))+)-)A4(A5(--+A1(--+))--))\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DataSet</th>\n",
        "      <th>E_train</th>\n",
        "      <th>E_test</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>MONK1</td>\n",
        "      <td>1</td>\n",
        "      <td>0.828704</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>MONK2</td>\n",
        "      <td>1</td>\n",
        "      <td>0.692130</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>MONK3</td>\n",
        "      <td>1</td>\n",
        "      <td>0.944444</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "  DataSet  E_train    E_test\n",
        "0   MONK1        1  0.828704\n",
        "1   MONK2        1  0.692130\n",
        "2   MONK3        1  0.944444"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assignment 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "def partition(data, fraction):\n",
      "    ldata = list(data)\n",
      "    random.shuffle(ldata)\n",
      "    breakPoint = int(len(ldata) * fraction)\n",
      "    return ldata[:breakPoint], ldata[breakPoint:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fractions = np.arange(0.3, 1, 0.1)\n",
      "d = []\n",
      "# loop over datasets\n",
      "for i in [0,2]:\n",
      "    row = []\n",
      "    # loop over fractions\n",
      "    for f in fractions:\n",
      "        train, val = partition(datasets[i], f)\n",
      "        # set initial tree\n",
      "        current_tree = buildTree(train, m.attributes)\n",
      "        ap_perf = 0\n",
      "        ct_perf = check(current_tree, val)\n",
      "        # stop when pruning doesn't ourperform the current tree\n",
      "        while ap_perf > ct_perf or ap_perf == 0:\n",
      "            if ap_perf != 0:\n",
      "                ct_perf = ap_perf\n",
      "            all_pruned = allPruned(current_tree)\n",
      "            checks = [check(t, val) for t in all_pruned]\n",
      "            ap_perf = max(checks)\n",
      "            # set current tree to best pruning tree\n",
      "            if ap_perf > ct_perf:\n",
      "                current_tree = all_pruned[checks.index(ap_perf)]\n",
      "                \n",
      "        row.append(1 - check(current_tree, testsets[i]))\n",
      "    d.append(row)\n",
      "\n",
      "df = DataFrame(d, index=[\"MONK1\", \"MONK3\"],columns=fractions)\n",
      "df.transpose().plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x10a51acd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBCCCGEEEIIIYTH+381KiLnWjnmdAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a524b10>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The optimal value for `fraction` cannot be estimated with just one test run, as the elements in the partitioning are randomly selected because of the `random.shuffle(ldata)` in `partition`. Therefore, we need to run a large number of simulations to obtain an estimate for `fraction`. We can reuse the code above and simple add a number of simulations. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fractions = np.arange(0.3, 1, 0.1)\n",
      "data = []\n",
      "nr_of_runs = 5000 # number of simulations per fraction per dataset\n",
      "# loop over datasets\n",
      "for i in [0,2]:\n",
      "    row = []\n",
      "    # loop over fractions\n",
      "    for f in fractions:\n",
      "        errors = []\n",
      "        for n in range(0,nr_of_runs): # execute n simulations\n",
      "            train, val = partition(datasets[i], f)\n",
      "            # set initial tree\n",
      "            current_tree = buildTree(train, m.attributes)\n",
      "            ap_perf = 0\n",
      "            ct_perf = check(current_tree, val)\n",
      "            # stop when pruning doesn't ourperform the current tree\n",
      "            while ap_perf > ct_perf or ap_perf == 0:\n",
      "                if ap_perf != 0:\n",
      "                    ct_perf = ap_perf\n",
      "                all_pruned = allPruned(current_tree)\n",
      "                checks = [check(t, val) for t in all_pruned]\n",
      "                ap_perf = max(checks)\n",
      "                # set current tree to best pruning tree\n",
      "                if ap_perf > ct_perf:\n",
      "                    current_tree = all_pruned[checks.index(ap_perf)]\n",
      "            errors.append(1 - check(current_tree, testsets[i]))\n",
      "        row.append(sum(errors) / len(errors)) # take the average simulation performance\n",
      "    data.append(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "max() arg is an empty sequence",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-79-8057ea1a95c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mall_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallPruned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mchecks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_pruned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0map_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# set current tree to best pruning tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0map_perf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mct_perf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_final = DataFrame(data, index=[\"MONK1\", \"MONK3\"],columns=fractions)\n",
      "df_final.transpose().plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plot above is based on **2000** simulations per fraction. From the plot we can see that the optimal value of `fraction` is somewhere around 0.7 for MONK1 and around 0.8 for MONK2. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "[[0.22476851851851837,\n",
        "  0.20460648148148144,\n",
        "  0.17814814814814808,\n",
        "  0.1676157407407407,\n",
        "  0.1611111111111111,\n",
        "  0.15527777777777776,\n",
        "  0.14754629629629623],\n",
        " [0.10486111111111118,\n",
        "  0.06037037037037034,\n",
        "  0.043564814814814806,\n",
        "  0.03810185185185186,\n",
        "  0.039861111111111125,\n",
        "  0.041388888888888885,\n",
        "  0.060000000000000026]]"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}